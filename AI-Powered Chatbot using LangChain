# ai_chatbot_langchain.py

from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)

conversation = ConversationChain(
    llm=llm,
    memory=ConversationBufferMemory()
)

# Chat with bot
while True:
    user_input = input("You: ")
    response = conversation.predict(input=user_input)
    print(f"Bot: {response}")
